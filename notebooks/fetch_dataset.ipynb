{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1da22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.utils import Bunch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59050be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dir():\n",
    "    \"\"\"Return the path of the scikit-uplift data dir.\n",
    "\n",
    "    This folder is used by some large dataset loaders to avoid downloading the data several times.\n",
    "\n",
    "    By default the data dir is set to a folder named ``scikit-uplift-data`` in the user home folder.\n",
    "\n",
    "    Returns:\n",
    "        string: The path to scikit-uplift data dir.\n",
    "\n",
    "    \"\"\"\n",
    "    return os.path.join(os.path.expanduser(\"~\"), \"scikit-uplift-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37c26365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_data_dir(path):\n",
    "    \"\"\"Creates a directory, which stores the datasets.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to scikit-uplift data dir.\n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18fa3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _download(url, dest_path, content_length_header_key='Content-Length'):\n",
    "    \"\"\"Download the file from url and save it locally.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL address, must be a string.\n",
    "        dest_path (str): Destination of the file.\n",
    "        content_length_header_key (str): The key in the HTTP response headers that lists the response size in bytes.\n",
    "            Used for progress bar.\n",
    "    \"\"\"\n",
    "    if isinstance(url, str):\n",
    "        req = requests.get(url, stream=True)\n",
    "        req.raise_for_status()\n",
    "\n",
    "        with open(dest_path, \"wb\") as fd:\n",
    "            total_size_in_bytes = int(req.headers.get(content_length_header_key, 0))\n",
    "            progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "            for chunk in req.iter_content(chunk_size=2 ** 20):\n",
    "                progress_bar.update(len(chunk))\n",
    "                fd.write(chunk)\n",
    "    else:\n",
    "        raise TypeError(\"URL must be a string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bffe0911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data(data_home, url, dest_subdir, dest_filename, download_if_missing,\n",
    "              content_length_header_key='Content-Length'):\n",
    "    \"\"\"Return the path to the dataset.\n",
    "\n",
    "    Args:\n",
    "        data_home (str): The path to scikit-uplift data dir.\n",
    "        url (str): The URL to the dataset.\n",
    "        dest_subdir (str): The name of the folder in which the dataset is stored.\n",
    "        dest_filename (str): The name of the dataset.\n",
    "        download_if_missing (bool): If False, raise a IOError if the data is not locally available instead of\n",
    "            trying to download the data from the source site.\n",
    "        content_length_header_key (str): The key in the HTTP response headers that lists the response size in bytes.\n",
    "            Used for progress bar.\n",
    "\n",
    "    Returns:\n",
    "        string: The path to the dataset.\n",
    "\n",
    "    \"\"\"\n",
    "    if data_home is None:\n",
    "        if dest_subdir is None:\n",
    "            data_dir = get_data_dir()\n",
    "        else:\n",
    "            data_dir = os.path.join(get_data_dir(), dest_subdir)\n",
    "    else:\n",
    "        if dest_subdir is None:\n",
    "            data_dir = os.path.abspath(data_home)\n",
    "        else:\n",
    "            data_dir = os.path.join(os.path.abspath(data_home), dest_subdir)\n",
    "\n",
    "    _create_data_dir(data_dir)\n",
    "\n",
    "    dest_path = os.path.join(data_dir, dest_filename)\n",
    "\n",
    "    if not os.path.isfile(dest_path):\n",
    "        if download_if_missing:\n",
    "            _download(url, dest_path, content_length_header_key)\n",
    "        else:\n",
    "            raise IOError(\"Dataset missing\")\n",
    "    return dest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76a11046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_data_dir(path=None):\n",
    "    \"\"\"Delete all the content of the data home cache.\n",
    "\n",
    "        Args:\n",
    "            path (str): The path to scikit-uplift data dir\n",
    "\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        path = get_data_dir()\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa6c40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_dataset(target_col='conversion', data_home=None, dest_subdir=None, download_if_missing=True,\n",
    "                    return_X_y_t=False):\n",
    "    \"\"\"Load and return dataset for promotion marketing campaig .\n",
    ".\n",
    "    Context\n",
    "    \n",
    "    Marketing Promotion Campaign\n",
    "    with a total of 6,400 customers data.\n",
    "\n",
    "    Content\n",
    "    This dataset show customer's brief information,\n",
    "    historical use of discount or BOGO(Buy One Get One) promotion,\n",
    "    offer has been made, and the conversion result(buy or not).\n",
    "    The conversion average value = $25\n",
    "    \n",
    "    Acknowledgements\n",
    "    This dataset is a fictional dataset for practicing purpose\n",
    "\n",
    "    Inspiration\n",
    "    \n",
    "    Predict customer's conversion rate\n",
    "    Uplift Modelling to maximizing marketing campaign and reducing campaign cost\n",
    "\n",
    "    Major columns:\n",
    "\n",
    "    * ``conversion`` (binary): target. 1/0 indicator, 1 = Customer purchased merchandise in the following two weeks.\n",
    "    * ``offer`` (str): treatment. The campaign the customer received (Discount/Buy One Get One/No Offer)\n",
    "\n",
    "    Read more in the :ref:`docs <dataset>`.\n",
    "\n",
    "    Args:\n",
    "        target_col (string, 'visit' or 'conversion', 'spend' or 'all', default='visit'): Selects which column from dataset\n",
    "            will be target\n",
    "        data_home (str): The path to the folder where datasets are stored.\n",
    "        dest_subdir (str): The name of the folder in which the dataset is stored.\n",
    "        download_if_missing (bool): Download the data if not present. Raises an IOError if False and data is missing.\n",
    "        return_X_y_t (bool, default=False): If True, returns (data, target, treatment) instead of a Bunch object.\n",
    "\n",
    "    Returns:\n",
    "        Bunch or tuple: dataset.\n",
    "\n",
    "        Bunch:\n",
    "            By default dictionary-like object, with the following attributes:\n",
    "\n",
    "                * ``data`` (DataFrame object): Dataset without target and treatment.\n",
    "                * ``target`` (Series or DataFrame object): Column target by values.\n",
    "                * ``treatment`` (Series object): Column treatment by values.\n",
    "                * ``DESCR`` (str): Description of the dataset.\n",
    "                * ``feature_names`` (list): Names of the features.\n",
    "                * ``target_name`` (str or list): Name of the target.\n",
    "                * ``treatment_name`` (str): Name of the treatment.\n",
    "\n",
    "        Tuple:\n",
    "            tuple (data, target, treatment) if `return_X_y` is True\n",
    "\n",
    "    References:\n",
    "        https://www.kaggle.com/davinwijaya/customer-retention\n",
    "\n",
    "    Example::\n",
    "\n",
    "        from sklift.datasets import fetch_dataset\n",
    "\n",
    "\n",
    "        dataset = fetch_dataset(target_col='conversion')\n",
    "        data, target, treatment = dataset.data, dataset.target, dataset.treatment\n",
    "\n",
    "        # alternative option\n",
    "        data, target, treatment = fetch_dataset(target_col='conversion', return_X_y_t=True)\n",
    "\n",
    "    See Also:\n",
    "\n",
    "        :func:`.fetch_lenta`: Load and return the Lenta dataset (classification).\n",
    "\n",
    "        :func:`.fetch_x5`: Load and return the X5 RetailHero dataset (classification).\n",
    "\n",
    "        :func:`.fetch_criteo`: Load and return the Criteo Uplift Prediction Dataset (classification).\n",
    "\n",
    "        :func:`.fetch_megafon`: Load and return the MegaFon Uplift Competition dataset (classification)\n",
    "    \"\"\"\n",
    "    target_cols = ['offer', 'conversion']\n",
    "    if target_col == 'all':\n",
    "        target_col = target_cols\n",
    "    elif target_col not in target_cols:\n",
    "        raise ValueError(f\"The target_col must be an element of {target_cols + ['all']}. \"\n",
    "                         f\"Got value target_col={target_col}.\")\n",
    "\n",
    "    url = 'https://scikit-uplift-material.s3.eu-north-1.amazonaws.com/data.csv.zip'\n",
    "    filename = url.split('/')[-1] \n",
    "    csv_path = _get_data(data_home=data_home, url=url, dest_subdir=dest_subdir,\n",
    "                         dest_filename=filename,\n",
    "                         download_if_missing=download_if_missing)\n",
    "\n",
    "    treatment_col = 'offer'\n",
    "\n",
    "    data = pd.read_csv(csv_path)\n",
    "    treatment, target = data[treatment_col], data[target_col]\n",
    "\n",
    "    data = data.drop(target_cols + [treatment_col], axis=1)\n",
    "\n",
    "    if return_X_y_t:\n",
    "        return data, target, treatment\n",
    "\n",
    "    feature_names = list(data.columns)\n",
    "\n",
    "    #module_path = os.path.dirname(os.path.abspath(__file__))\n",
    "    #with open(os.path.join(module_path, 'descr', 'dataset.rst')) as rst_file:\n",
    "        #fdescr = rst_file.read()\n",
    "\n",
    "    return Bunch(data=data, target=target, treatment=treatment, #DESCR=fdescr,\n",
    "                 feature_names=feature_names, target_name=target_col, treatment_name=treatment_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42ba84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
